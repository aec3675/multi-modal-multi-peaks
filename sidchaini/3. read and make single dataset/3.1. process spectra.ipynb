{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii as astropy_ascii\n",
    "from astropy.table import Table\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumProcessor:\n",
    "    def __init__(self, metadata_path, spectra_dir, output_dir=None):\n",
    "        \"\"\"\n",
    "        Initialize the processor with paths to metadata and spectra.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        metadata_path : str\n",
    "            Path to the metadata CSV file\n",
    "        spectra_dir : str\n",
    "            Directory containing the spectra files\n",
    "        output_dir : str, optional\n",
    "            Directory to save processed spectra\n",
    "        \"\"\"\n",
    "        self.metadata_path = metadata_path\n",
    "        self.spectra_dir = spectra_dir\n",
    "        self.output_dir = output_dir or os.path.join(spectra_dir, \"processed\")\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        # Load metadata\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "        # Define standard wavelength grid for resampling\n",
    "        # This range covers optical to near-IR (common for supernovae)\n",
    "        self.wavelength_grid = np.linspace(3500, 10000, 1000)\n",
    "\n",
    "    def read_spectrum(self, filepath):\n",
    "        \"\"\"\n",
    "        Read a spectrum file in any format.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        filepath : str\n",
    "            Path to the spectrum file\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        wavelength : numpy.ndarray\n",
    "            Wavelength array\n",
    "        flux : numpy.ndarray\n",
    "            Flux array\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filepath)\n",
    "        extension = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "        try:\n",
    "            # ECSV format (DESI spectra)\n",
    "            if extension == \".ecsv\":\n",
    "                data = Table.read(filepath, format=\"ascii.ecsv\")\n",
    "                wavelength = np.array(data[\"WAVE\"])\n",
    "                flux = np.array(data[\"FLUX\"])\n",
    "\n",
    "            # ASCII format for ePESSTO data\n",
    "            elif extension == \".asci\":\n",
    "                data = np.loadtxt(filepath)\n",
    "                wavelength = data[:, 0]\n",
    "                flux = data[:, 1]\n",
    "\n",
    "            # CAT format\n",
    "            elif extension == \".cat\":\n",
    "                data = np.loadtxt(filepath)\n",
    "                wavelength = data[:, 0]\n",
    "                flux = data[:, 1]\n",
    "\n",
    "            # DAT format (model spectra)\n",
    "            elif extension == \".dat\":\n",
    "                data = np.loadtxt(filepath)\n",
    "                wavelength = data[:, 0]\n",
    "                flux = data[:, 1]\n",
    "\n",
    "            # FITS format\n",
    "            elif extension in [\".fits\", \".fit\", \".fts\"]:\n",
    "                with fits.open(filepath) as hdul:\n",
    "                    # Try to figure out the correct extension and column names\n",
    "                    # This might need adjustment based on your specific FITS files\n",
    "                    for hdu in hdul:\n",
    "                        if isinstance(hdu, fits.BinTableHDU):\n",
    "                            table = Table(hdu.data)\n",
    "                            # Look for common column names for wavelength and flux\n",
    "                            for wave_col in [\n",
    "                                \"WAVE\",\n",
    "                                \"WAVELENGTH\",\n",
    "                                \"LAMBDA\",\n",
    "                                \"LOGLAM\",\n",
    "                                \"CRVAL1\",\n",
    "                            ]:\n",
    "                                if wave_col in table.colnames:\n",
    "                                    wavelength = np.array(table[wave_col])\n",
    "                                    break\n",
    "                            for flux_col in [\"FLUX\", \"FLAM\", \"SPEC\", \"DATA\"]:\n",
    "                                if flux_col in table.colnames:\n",
    "                                    flux = np.array(table[flux_col])\n",
    "                                    break\n",
    "                            break\n",
    "\n",
    "            # Cal_galsub format\n",
    "            elif \"_galsub\" in filename or \".cal_galsub\" in filename:\n",
    "                data = np.loadtxt(filepath, skiprows=2)\n",
    "                wavelength = data[:, 0]\n",
    "                flux = data[:, 1]\n",
    "\n",
    "            # Standard ASCII format with two columns (wavelength, flux)\n",
    "            else:\n",
    "                # Try different reading approaches\n",
    "                try:\n",
    "                    # Try standard loadtxt first\n",
    "                    data = np.loadtxt(filepath)\n",
    "                    wavelength = data[:, 0]\n",
    "                    flux = data[:, 1]\n",
    "                except:\n",
    "                    # If that fails, try astropy.io.ascii which can handle more formats\n",
    "                    data = astropy_ascii.read(filepath)\n",
    "                    # Try to identify the wavelength and flux columns\n",
    "                    if len(data.colnames) >= 2:\n",
    "                        wavelength = np.array(data[data.colnames[0]])\n",
    "                        flux = np.array(data[data.colnames[1]])\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"Could not identify wavelength and flux columns in {filepath}\"\n",
    "                        )\n",
    "\n",
    "            return wavelength, flux\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filepath}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def preprocess_spectrum(self, wavelength, flux):\n",
    "        \"\"\"\n",
    "        Preprocess a spectrum by:\n",
    "        1. Removing NaN or infinite values\n",
    "        2. Removing negative wavelengths\n",
    "        3. Sorting by wavelength\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        wavelength : numpy.ndarray\n",
    "            Wavelength array\n",
    "        flux : numpy.ndarray\n",
    "            Flux array\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        wavelength : numpy.ndarray\n",
    "            Cleaned wavelength array\n",
    "        flux : numpy.ndarray\n",
    "            Cleaned flux array\n",
    "        \"\"\"\n",
    "        if wavelength is None or flux is None:\n",
    "            return None, None\n",
    "\n",
    "        # Make sure arrays are the same length\n",
    "        min_len = min(len(wavelength), len(flux))\n",
    "        wavelength = wavelength[:min_len]\n",
    "        flux = flux[:min_len]\n",
    "\n",
    "        # Remove NaN and inf values\n",
    "        mask = np.isfinite(wavelength) & np.isfinite(flux)\n",
    "        wavelength = wavelength[mask]\n",
    "        flux = flux[mask]\n",
    "\n",
    "        # Remove negative wavelengths\n",
    "        mask = wavelength > 0\n",
    "        wavelength = wavelength[mask]\n",
    "        flux = flux[mask]\n",
    "\n",
    "        # Sort by wavelength\n",
    "        sort_idx = np.argsort(wavelength)\n",
    "        wavelength = wavelength[sort_idx]\n",
    "        flux = flux[sort_idx]\n",
    "\n",
    "        return wavelength, flux\n",
    "\n",
    "    def normalize_spectrum(self, flux):\n",
    "        \"\"\"\n",
    "        Normalize a spectrum by:\n",
    "        1. Subtracting the mean\n",
    "        2. Dividing by the standard deviation\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        flux : numpy.ndarray\n",
    "            Flux array\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        norm_flux : numpy.ndarray\n",
    "            Normalized flux array\n",
    "        \"\"\"\n",
    "        if flux is None or len(flux) == 0:\n",
    "            return None\n",
    "\n",
    "        # Remove outliers (optional)\n",
    "        # This can help with extreme values that might skew normalization\n",
    "        q1, q3 = np.percentile(flux, [1, 99])\n",
    "        iqr = q3 - q1\n",
    "        mask = (flux >= q1 - 1.5 * iqr) & (flux <= q3 + 1.5 * iqr)\n",
    "\n",
    "        if np.sum(mask) > len(flux) * 0.5:  # If we still have enough data\n",
    "            mean = np.mean(flux[mask])\n",
    "            std = np.std(flux[mask])\n",
    "        else:\n",
    "            mean = np.mean(flux)\n",
    "            std = np.std(flux)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if std == 0:\n",
    "            std = 1.0\n",
    "\n",
    "        norm_flux = (flux - mean) / std\n",
    "\n",
    "        return norm_flux\n",
    "\n",
    "    def resample_spectrum(self, wavelength, flux):\n",
    "        \"\"\"\n",
    "        Resample a spectrum to a standard wavelength grid using interpolation.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        wavelength : numpy.ndarray\n",
    "            Original wavelength array\n",
    "        flux : numpy.ndarray\n",
    "            Original flux array\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        resampled_flux : numpy.ndarray\n",
    "            Resampled flux array on the standard wavelength grid\n",
    "        \"\"\"\n",
    "        if wavelength is None or flux is None or len(wavelength) < 2:\n",
    "            return None\n",
    "\n",
    "        # Check wavelength coverage against the standard grid\n",
    "        if (\n",
    "            wavelength.min() > self.wavelength_grid.min()\n",
    "            or wavelength.max() < self.wavelength_grid.max()\n",
    "        ):\n",
    "            # Spectrum doesn't cover the entire standard grid\n",
    "            # We'll interpolate within range and set values outside to NaN\n",
    "            valid_range = (self.wavelength_grid >= wavelength.min()) & (\n",
    "                self.wavelength_grid <= wavelength.max()\n",
    "            )\n",
    "\n",
    "            # Create interpolation function for the valid range\n",
    "            f = interpolate.interp1d(\n",
    "                wavelength, flux, bounds_error=False, fill_value=np.nan\n",
    "            )\n",
    "            resampled_flux = np.full_like(self.wavelength_grid, np.nan)\n",
    "            resampled_flux[valid_range] = f(self.wavelength_grid[valid_range])\n",
    "        else:\n",
    "            # Spectrum covers the entire standard grid\n",
    "            f = interpolate.interp1d(\n",
    "                wavelength, flux, bounds_error=False, fill_value=np.nan\n",
    "            )\n",
    "            resampled_flux = f(self.wavelength_grid)\n",
    "\n",
    "        return resampled_flux\n",
    "\n",
    "    def process_all_spectra(self):\n",
    "        \"\"\"\n",
    "        Process all spectra in the directory and create a tensor for machine learning.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        spectra_tensor : numpy.ndarray\n",
    "            3D tensor containing all processed spectra\n",
    "            Shape: (n_spectra, n_wavelength_points, 1)\n",
    "        metadata_subset : pandas.DataFrame\n",
    "            Metadata for the successfully processed spectra\n",
    "        \"\"\"\n",
    "        processed_spectra = []\n",
    "        successful_indices = []\n",
    "\n",
    "        for i, row in tqdm(\n",
    "            self.metadata.iterrows(),\n",
    "            total=len(self.metadata),\n",
    "            desc=\"Processing spectra\",\n",
    "        ):\n",
    "            try:\n",
    "                # Get filename from metadata\n",
    "                filename = row.get(\"filename\", \"\")\n",
    "                if not filename:\n",
    "                    # If filename not in metadata, try to match based on other fields\n",
    "                    # This depends on your metadata structure\n",
    "                    continue\n",
    "\n",
    "                filepath = os.path.join(self.spectra_dir, filename)\n",
    "                if not os.path.exists(filepath):\n",
    "                    # Try to find the file by fuzzy matching\n",
    "                    possible_files = glob.glob(\n",
    "                        os.path.join(\n",
    "                            self.spectra_dir, f\"*{os.path.splitext(filename)[0]}*\"\n",
    "                        )\n",
    "                    )\n",
    "                    if possible_files:\n",
    "                        filepath = possible_files[0]\n",
    "                    else:\n",
    "                        print(f\"Could not find file for {filename}\")\n",
    "                        continue\n",
    "\n",
    "                # Read and process the spectrum\n",
    "                wavelength, flux = self.read_spectrum(filepath)\n",
    "                wavelength, flux = self.preprocess_spectrum(wavelength, flux)\n",
    "\n",
    "                # Check if we have valid data\n",
    "                if wavelength is None or flux is None or len(wavelength) < 10:\n",
    "                    print(f\"Insufficient data in {filename}, skipping\")\n",
    "                    continue\n",
    "\n",
    "                # Normalize and resample\n",
    "                norm_flux = self.normalize_spectrum(flux)\n",
    "                resampled_flux = self.resample_spectrum(wavelength, norm_flux)\n",
    "\n",
    "                # Check if resampling was successful\n",
    "                if resampled_flux is None or np.all(np.isnan(resampled_flux)):\n",
    "                    print(f\"Resampling failed for {filename}, skipping\")\n",
    "                    continue\n",
    "\n",
    "                # Fill NaN values with zeros or interpolate\n",
    "                # This is a simple approach; you might want something more sophisticated\n",
    "                mask = np.isnan(resampled_flux)\n",
    "                if np.any(mask):\n",
    "                    # If less than 30% NaN, interpolate\n",
    "                    if np.sum(mask) < 0.3 * len(resampled_flux):\n",
    "                        valid_indices = np.where(~mask)[0]\n",
    "                        valid_values = resampled_flux[valid_indices]\n",
    "                        nan_indices = np.where(mask)[0]\n",
    "\n",
    "                        # Simple linear interpolation\n",
    "                        interp_values = np.interp(\n",
    "                            nan_indices,\n",
    "                            valid_indices,\n",
    "                            valid_values,\n",
    "                            left=0,  # Or another strategy for extrapolation\n",
    "                            right=0,\n",
    "                        )\n",
    "                        resampled_flux[nan_indices] = interp_values\n",
    "                    else:\n",
    "                        # Too many NaNs, skip this spectrum\n",
    "                        print(f\"Too many NaN values in {filename}, skipping\")\n",
    "                        continue\n",
    "\n",
    "                # Reshape for the tensor\n",
    "                reshaped_flux = resampled_flux.reshape(1, -1, 1)\n",
    "                processed_spectra.append(reshaped_flux)\n",
    "                successful_indices.append(i)\n",
    "\n",
    "                # Optional: save the processed spectrum\n",
    "                if self.output_dir:\n",
    "                    output_file = os.path.join(\n",
    "                        self.output_dir, f\"processed_{os.path.basename(filename)}.npy\"\n",
    "                    )\n",
    "                    np.save(output_file, reshaped_flux)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {row.get('filename', 'unknown')}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Combine all processed spectra into a tensor\n",
    "        if not processed_spectra:\n",
    "            print(\"No spectra were successfully processed\")\n",
    "            return None, None\n",
    "\n",
    "        # Convert list of arrays to a single 3D tensor\n",
    "        # Each spectrum is a 1 x n_wavelength_points x 1 array\n",
    "        # We stack along the first dimension to get n_spectra x n_wavelength_points x 1\n",
    "        spectra_tensor = np.vstack(processed_spectra)\n",
    "\n",
    "        # Get the subset of metadata for successfully processed spectra\n",
    "        metadata_subset = self.metadata.iloc[successful_indices].reset_index(drop=True)\n",
    "\n",
    "        return spectra_tensor, metadata_subset\n",
    "\n",
    "    def visualize_spectra(self, spectra_tensor, n_samples=5):\n",
    "        \"\"\"\n",
    "        Visualize a random sample of processed spectra.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        spectra_tensor : numpy.ndarray\n",
    "            3D tensor containing all processed spectra\n",
    "        n_samples : int, optional\n",
    "            Number of spectra to visualize\n",
    "        \"\"\"\n",
    "        if spectra_tensor is None or spectra_tensor.shape[0] == 0:\n",
    "            print(\"No spectra to visualize\")\n",
    "            return\n",
    "\n",
    "        # Select random indices\n",
    "        n_spectra = spectra_tensor.shape[0]\n",
    "        indices = np.random.choice(n_spectra, min(n_samples, n_spectra), replace=False)\n",
    "\n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, idx in enumerate(indices):\n",
    "            plt.subplot(n_samples, 1, i + 1)\n",
    "            plt.plot(self.wavelength_grid, spectra_tensor[idx, :, 0])\n",
    "            plt.title(f\"Spectrum {idx}\")\n",
    "            plt.xlabel(\"Wavelength (Å)\")\n",
    "            plt.ylabel(\"Normalized Flux\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, \"sample_spectra.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"../1. download ALL wise data/wiserep_spectra_combined.csv\"\n",
    "spectra_dir = \"../1. download ALL wise data/wiserep_data/spectra/\"\n",
    "output_dir = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2d/ht34x6mn7hx9d1sv4g_j8nfr0000gn/T/ipykernel_66029/3461933826.py:35: DtypeWarning: Columns (0,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.metadata = pd.read_csv(metadata_path)\n"
     ]
    }
   ],
   "source": [
    "# Create processor\n",
    "processor = SpectrumProcessor(\n",
    "    metadata_path=metadata_path,\n",
    "    spectra_dir=spectra_dir,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spectra...\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing spectra...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398c0d3c76454e869de032f4bfc59d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing spectra:   0%|          | 0/54005 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectra were successfully processed\n"
     ]
    }
   ],
   "source": [
    "spectra_tensor, metadata_subset = processor.process_all_spectra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
